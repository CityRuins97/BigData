{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d04070-084b-4e86-bafa-ec9da6b97b69",
   "metadata": {},
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6545196-8cbc-41c5-b74b-e860b1ad3fbd",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4dfdac-218d-4658-8b2f-9e3634b66517",
   "metadata": {},
   "source": [
    "### **Reading a Stream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4cc739-87e8-40fe-8b61-bc2f1e28a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a36928-8098-41f5-b4ed-d5b5f8fd426d",
   "metadata": {},
   "source": [
    "* For this task, we’ll just generate data using the rate source (see example in the notes).\n",
    "– Create an input stream from the rate format using 1 row per second\n",
    "– Recall that this outputs values with a timestamp. The values start at 0 and increase by 1 each\n",
    "time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a05d1-14a9-48c4-85d9-bb6525479174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"rate\").option(\"rowPerSecond\", 1).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29747a-ae28-4752-b017-4578a75a620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_writestream = df.writeStream.outputMode(\"append\").format(\"console\").start()\n",
    "df_writestream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57060db3-07ef-4504-8a03-bf3a0be54280",
   "metadata": {},
   "source": [
    "### **Transform/Aggregation Step**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42555ab-ec7a-480b-9472-db8588396036",
   "metadata": {},
   "source": [
    "* Now, we’ll do some basic practice with windowing summarizations! To do a window operation and\n",
    "outputting, we’ll need to add a watermark and use .groupBy() to specify the windows.\n",
    "– Add a watermark that relies in the timestamp column that uses a five second watermark\n",
    "– Import the window() function and use it with .groupBy() to create windows that are 30 seconds\n",
    "long with no overlap\n",
    "– We’ll simply sum the values within that window, so add the .sum() aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07681d-443a-49f3-a4e0-4ee29a06d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watermark = df.withWatermark(\"timestamp\",\"5 seconds\").groupby(window(df.timestamp,\"30 seconds\",\"30 seconds\")).sum("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c370e94-adf5-49d4-9c88-770a687c7a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
